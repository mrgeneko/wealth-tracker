services:
  scrapers:
    build:
      context: .
      dockerfile: docker/Dockerfile.scrapers
    platform: linux/amd64
    container_name: wealth-tracker-scrapers
    environment:
      # Use internal Docker DNS hostname for Kafka instead of localhost
      KAFKA_BROKERS: kafka:9092
      # Unified topic for all published price data
      KAFKA_TOPIC: price_data
      # Health endpoint port exposed by the daemon
      HEALTH_PORT: "3002"
      # Yahoo batch tuning (chunking, delays, retries)
      YAHOO_CHUNK_SIZE: "2"
      YAHOO_DELAY_MS: "5000"
      YAHOO_MAX_RETRIES: "4"
      YAHOO_BACKOFF_BASE_MS: "1000"
    volumes:
      - ./logs:/usr/src/app/logs
      - ./data:/usr/src/app/data
    ports:
      - "5901:5901"
      - "3002:3002"
    deploy:
      resources:
        limits:
          memory: 8g

  dashboard:
    build:
      context: .
      dockerfile: dashboard/Dockerfile
    container_name: wealth-tracker-dashboard
    restart: unless-stopped
    depends_on:
      - kafka
      - mysql
    environment:
      KAFKA_BROKERS: kafka:9092
      KAFKA_TOPIC: price_data
      KAFKA_GROUP_ID: dashboard-group
      PORT: 3001
      MYSQL_HOST: mysql
      MYSQL_PORT: 3306
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      BASIC_AUTH_USER: ${BASIC_AUTH_USER}
      BASIC_AUTH_PASSWORD: ${BASIC_AUTH_PASSWORD}
    volumes:
      - ./logs:/usr/src/app/logs
      - ./config/assets_liabilities.json:/assets_liabilities.json:ro
      - ./config:/app/config:ro
    ports:
      - "3001:3001"

  mysql:
    image: mysql:8.0
    container_name: wealth-tracker-mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - "3306:3306"
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost" ]
      interval: 10s
      timeout: 5s
      retries: 5
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    container_name: wealth-tracker-kafka
    image: confluentinc/cp-kafka:7.4.0
    restart: unless-stopped
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Ensure producers auto-create topics when first message is sent
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9094:9092"
      - "9093:9093"
    healthcheck:
      test: [ "CMD", "bash", "-c", "kafka-topics --bootstrap-server localhost:9092 --list || exit 1" ]
      interval: 10s
      retries: 10
      start_period: 10s

  kafka-consumer:
    build:
      context: .
      dockerfile: docker/Dockerfile.consumer
    container_name: wealth-tracker-kafka-consumer
    depends_on:
      - kafka
      - mysql
    restart: unless-stopped
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: price_data
      MYSQL_HOST: mysql
      MYSQL_PORT: 3306
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
    # command can be omitted if set in Dockerfile

  log-rotator:
    image: alpine:3.19
    container_name: wealth-tracker-log-rotator
    restart: unless-stopped
    volumes:
      - ./logs:/usr/src/app/logs
      - ./scripts/maintenance/rotate-logs.sh:/usr/local/bin/rotate-logs.sh:ro
    entrypoint: [ "sh", "/usr/local/bin/rotate-logs.sh", "/usr/src/app/logs", "7", "1", "300" ]
    healthcheck:
      test: [ "CMD", "sh", "-c", "test -x /usr/local/bin/rotate-logs.sh || exit 1" ]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
volumes:
  mysql_data:
